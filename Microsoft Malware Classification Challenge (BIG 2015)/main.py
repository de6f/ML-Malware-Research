# -*- coding: utf-8 -*-

"""
    Eliminate randomness using constant seed values
"""
from numpy.random import seed
seed(1)
from tensorflow import set_random_seed
set_random_seed(2)

import os
import csv
import matplotlib.pyplot as plt

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

#### Ayarlar

labelFile = 'trainLabels.csv'
imageDir = '.\\imageData_nataraj'
trainDir = '.\\train'
testDir = '.\\test'
validationDir = '.\\validation'
model_file = 'first_try.h5'

testRate = 0.4
validRate = 0.1

makeDirs = True
batch_size = 10
train_epochs = 10

#### Ayarlar


with open(labelFile, "r") as csvFile:
    readCSV = csv.reader(csvFile, delimiter=',')
    """
        The first row shows column names
    """
    next(readCSV)
    labels = {}
    for row in readCSV:
        labels[row[0]] = row[1] 

"""
    Get image list from the directory and arrange to seperate dictionaries
"""

imgFiles = os.listdir(imageDir)
imgFiles = list(filter(lambda x: x.endswith(".png"), imgFiles))

trainCount = int(len(imgFiles) * (1 - validRate - testRate))
validCount = int(len(imgFiles) * validRate)
testCount = int(len(imgFiles) * testRate)

trainFiles = imgFiles[:trainCount]
validFiles = imgFiles[trainCount:trainCount + validCount]
testFiles = imgFiles[trainCount + validCount:]

def copyFiles(copyDir, images, makeDirs=False):
    if makeDirs:
        os.mkdir(copyDir + '\\1')
        os.mkdir(copyDir + '\\2')
        os.mkdir(copyDir + '\\3')
        os.mkdir(copyDir + '\\4')
        os.mkdir(copyDir + '\\5')
        os.mkdir(copyDir + '\\6')
        os.mkdir(copyDir + '\\7')
        os.mkdir(copyDir + '\\8')
        os.mkdir(copyDir + '\\9')
    for img in images:
        os.replace(imageDir + '\\' + img, copyDir + '\\' + \
                  labels[img.split('_')[0]] + '\\' + img)

if makeDirs:
    os.mkdir(trainDir)
    os.mkdir(testDir)
    os.mkdir(validationDir)

copyFiles(trainDir, trainFiles, makeDirs)
copyFiles(validationDir, validFiles, makeDirs)
copyFiles(testDir, testFiles, makeDirs)

"""
    Network model
"""

def create_model():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), input_shape=(30, 30, 1), padding='same'))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(32, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
    model.add(Dense(64))
    model.add(Activation('relu'))
    model.add(Dropout(0.3))
    model.add(Dense(units=9, activation='softmax'))
    
    model.compile(optimizer='adam', loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    return model
    
model = create_model()

"""
    Load images and train model
"""

train_data = ImageDataGenerator(rescale=1./255)
train_gen = train_data.flow_from_directory(
        'train',
        target_size=(30, 30),
        color_mode='grayscale',
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=True)

valid_data = ImageDataGenerator(rescale=1./255)
valid_gen = valid_data.flow_from_directory(
        'validation',
        target_size=(30, 30),
        color_mode='grayscale',
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=True)

test_data = ImageDataGenerator(rescale=1./255)
test_gen = test_data.flow_from_directory(
        'test',
        target_size=(30, 30),
        color_mode='grayscale',
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False)


model.fit_generator(
        train_gen,
        steps_per_epoch=(train_gen.samples / batch_size),
        epochs=train_epochs,
        validation_data=valid_gen,
        validation_steps=100)

model.save_weights(model_file)

"""
    Evaluate the model and show the metrics
"""

import numpy as np
from sklearn.metrics import classification_report

model = create_model()
if os.path.exists(model_file):
    model.load_weights(model_file)

test_steps_per_epoch = np.math.ceil(test_gen.samples / test_gen.batch_size)
predictions = model.predict_generator(test_gen, steps=test_steps_per_epoch)

# Get most likely class
predicted_classes = np.argmax(predictions, axis=1)
true_classes = test_gen.classes
class_labels = list(test_gen.class_indices.keys())

report = classification_report(true_classes, predicted_classes, target_names=class_labels)
print(report)


"""
    Plot ROC curves and calculate AUC scores
    https://scikit-learn.org/0.15/auto_examples/plot_roc.html
"""

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelBinarizer

def multiclass_roc_auc(y_true, y_score):
    lb = LabelBinarizer()
    lb.fit(y_true)
    
    y_true = lb.transform(y_true)
    y_score = lb.transform(y_score)
    
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(y_true.shape[1]):
        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])
        
    fpr["micro"], tpr["micro"], _ = roc_curve(y_true.ravel(), y_score.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
    
    plt.figure()
    plt.plot(fpr["micro"], tpr["micro"],
         label='micro-average ROC curve (area = {0:0.2f})'
               ''.format(roc_auc["micro"]))
    for i in range(y_true.shape[1]):
        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'
                                   ''.format(i, roc_auc[i]))

    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")
    plt.show()
    
    return roc_auc

multiclass_roc_auc(true_classes, predicted_classes)

"""
    Plot confusion matrix
"""

import seaborn as sn
import pandas as pd

from sklearn.metrics import confusion_matrix

array = confusion_matrix(true_classes, predicted_classes)

df_cm = pd.DataFrame(array, index = [i for i in range(9)], columns = [i for i in range(9)])
plt.figure(figsize =(9,9))
sn.heatmap(df_cm, annot=True)
